alg_name: sta
layers: [20]
# Use HuggingFace repo/path format - SAEs will be automatically downloaded
# Format: huggingface_repo_id:path_within_repo
sae_paths: ['google/gemma-scope-9b-pt-res:layer_20/width_16k/average_l0_114']
# Alternative examples:
# sae_paths: ['google/gemma-scope-9b-it-res:layer_20/width_16k/average_l0_91']
# sae_paths: ['google/gemma-scope-9b-pt-res:layer_24/width_16k/average_l0_114']
trims: [0.65]
mode: act_and_freq

multiple_choice: false
save_activations: True # set to True to save the activations of the model




